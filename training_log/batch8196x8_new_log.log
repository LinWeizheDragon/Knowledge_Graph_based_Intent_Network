reading train and test user-item set ...
combinating train_cf and kg data ...
building the graph ...
Begin to load interaction triples ...

Begin to load knowledge graph triples ...
building the adj mat ...
Begin to build sparse relation matrix ...
start training ...
az-wus2-a100-worker-00030:7342:7342 [0] NCCL INFO Bootstrap : Using eth0:192.168.0.33<0>
az-wus2-a100-worker-00030:7342:7342 [0] NCCL INFO Plugin Path : /opt/nccl-rdma-sharp-plugins/lib/libnccl-net.so
az-wus2-a100-worker-00030:7342:7342 [0] NCCL INFO P2P plugin IBext
az-wus2-a100-worker-00030:7342:7342 [0] NCCL INFO NCCL_IB_PCI_RELAXED_ORDERING set by environment to 1.
az-wus2-a100-worker-00030:7342:7342 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_1:1/IB/SHARP [2]mlx5_2:1/IB/SHARP [3]mlx5_3:1/IB/SHARP [4]mlx5_4:1/IB/SHARP [5]mlx5_5:1/IB/SHARP [6]mlx5_6:1/IB/SHARP [7]mlx5_7:1/IB/SHARP ; OOB eth0:192.168.0.33<0>
az-wus2-a100-worker-00030:7342:7342 [0] NCCL INFO Using network IBext
NCCL version 2.8.4+cuda11.1
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO NCCL_NET_GDR_LEVEL set by environment to SYS
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Trees [0] 0/-1/-1->1->2 [1] 0/-1/-1->1->2 [2] 0/-1/-1->1->2 [3] 0/-1/-1->1->2 [4] 0/-1/-1->1->2 [5] 0/-1/-1->1->2 [6] 0/-1/-1->1->2 [7] 0/-1/-1->1->2 [8] 0/-1/-1->1->2 [9] 0/-1/-1->1->2 [10] 0/-1/-1->1->2 [11] 0/-1/-1->1->2 [12] 0/-1/-1->1->2 [13] 0/-1/-1->1->2 [14] 0/-1/-1->1->2 [15] 0/-1/-1->1->2 [16] 0/-1/-1->1->2 [17] 0/-1/-1->1->2 [18] 0/-1/-1->1->2 [19] 0/-1/-1->1->2 [20] 0/-1/-1->1->2 [21] 0/-1/-1->1->2 [22] 0/-1/-1->1->2 [23] 0/-1/-1->1->2
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Trees [0] 2/-1/-1->3->4 [1] 2/-1/-1->3->4 [2] 2/-1/-1->3->4 [3] 2/-1/-1->3->4 [4] 2/-1/-1->3->4 [5] 2/-1/-1->3->4 [6] 2/-1/-1->3->4 [7] 2/-1/-1->3->4 [8] 2/-1/-1->3->4 [9] 2/-1/-1->3->4 [10] 2/-1/-1->3->4 [11] 2/-1/-1->3->4 [12] 2/-1/-1->3->4 [13] 2/-1/-1->3->4 [14] 2/-1/-1->3->4 [15] 2/-1/-1->3->4 [16] 2/-1/-1->3->4 [17] 2/-1/-1->3->4 [18] 2/-1/-1->3->4 [19] 2/-1/-1->3->4 [20] 2/-1/-1->3->4 [21] 2/-1/-1->3->4 [22] 2/-1/-1->3->4 [23] 2/-1/-1->3->4
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Setting affinity for GPU 6 to ffff,0000ffff
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Setting affinity for GPU 4 to ffff,0000ffff
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Trees [0] 1/-1/-1->2->3 [1] 1/-1/-1->2->3 [2] 1/-1/-1->2->3 [3] 1/-1/-1->2->3 [4] 1/-1/-1->2->3 [5] 1/-1/-1->2->3 [6] 1/-1/-1->2->3 [7] 1/-1/-1->2->3 [8] 1/-1/-1->2->3 [9] 1/-1/-1->2->3 [10] 1/-1/-1->2->3 [11] 1/-1/-1->2->3 [12] 1/-1/-1->2->3 [13] 1/-1/-1->2->3 [14] 1/-1/-1->2->3 [15] 1/-1/-1->2->3 [16] 1/-1/-1->2->3 [17] 1/-1/-1->2->3 [18] 1/-1/-1->2->3 [19] 1/-1/-1->2->3 [20] 1/-1/-1->2->3 [21] 1/-1/-1->2->3 [22] 1/-1/-1->2->3 [23] 1/-1/-1->2->3
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Trees [0] 3/-1/-1->4->5 [1] 3/-1/-1->4->5 [2] 3/-1/-1->4->5 [3] 3/-1/-1->4->5 [4] 3/-1/-1->4->5 [5] 3/-1/-1->4->5 [6] 3/-1/-1->4->5 [7] 3/-1/-1->4->5 [8] 3/-1/-1->4->5 [9] 3/-1/-1->4->5 [10] 3/-1/-1->4->5 [11] 3/-1/-1->4->5 [12] 3/-1/-1->4->5 [13] 3/-1/-1->4->5 [14] 3/-1/-1->4->5 [15] 3/-1/-1->4->5 [16] 3/-1/-1->4->5 [17] 3/-1/-1->4->5 [18] 3/-1/-1->4->5 [19] 3/-1/-1->4->5 [20] 3/-1/-1->4->5 [21] 3/-1/-1->4->5 [22] 3/-1/-1->4->5 [23] 3/-1/-1->4->5
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Setting affinity for GPU 5 to ffff,0000ffff
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Setting affinity for GPU 3 to ffff,0000ffff
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Trees [0] 4/-1/-1->5->6 [1] 4/-1/-1->5->6 [2] 4/-1/-1->5->6 [3] 4/-1/-1->5->6 [4] 4/-1/-1->5->6 [5] 4/-1/-1->5->6 [6] 4/-1/-1->5->6 [7] 4/-1/-1->5->6 [8] 4/-1/-1->5->6 [9] 4/-1/-1->5->6 [10] 4/-1/-1->5->6 [11] 4/-1/-1->5->6 [12] 4/-1/-1->5->6 [13] 4/-1/-1->5->6 [14] 4/-1/-1->5->6 [15] 4/-1/-1->5->6 [16] 4/-1/-1->5->6 [17] 4/-1/-1->5->6 [18] 4/-1/-1->5->6 [19] 4/-1/-1->5->6 [20] 4/-1/-1->5->6 [21] 4/-1/-1->5->6 [22] 4/-1/-1->5->6 [23] 4/-1/-1->5->6
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Setting affinity for GPU 2 to ffff,0000ffff
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Trees [0] 5/-1/-1->6->7 [1] 5/-1/-1->6->7 [2] 5/-1/-1->6->7 [3] 5/-1/-1->6->7 [4] 5/-1/-1->6->7 [5] 5/-1/-1->6->7 [6] 5/-1/-1->6->7 [7] 5/-1/-1->6->7 [8] 5/-1/-1->6->7 [9] 5/-1/-1->6->7 [10] 5/-1/-1->6->7 [11] 5/-1/-1->6->7 [12] 5/-1/-1->6->7 [13] 5/-1/-1->6->7 [14] 5/-1/-1->6->7 [15] 5/-1/-1->6->7 [16] 5/-1/-1->6->7 [17] 5/-1/-1->6->7 [18] 5/-1/-1->6->7 [19] 5/-1/-1->6->7 [20] 5/-1/-1->6->7 [21] 5/-1/-1->6->7 [22] 5/-1/-1->6->7 [23] 5/-1/-1->6->7
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Setting affinity for GPU 1 to ffff,0000ffff
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Trees [0] 6/-1/-1->7->-1 [1] 6/-1/-1->7->-1 [2] 6/-1/-1->7->-1 [3] 6/-1/-1->7->-1 [4] 6/-1/-1->7->-1 [5] 6/-1/-1->7->-1 [6] 6/-1/-1->7->-1 [7] 6/-1/-1->7->-1 [8] 6/-1/-1->7->-1 [9] 6/-1/-1->7->-1 [10] 6/-1/-1->7->-1 [11] 6/-1/-1->7->-1 [12] 6/-1/-1->7->-1 [13] 6/-1/-1->7->-1 [14] 6/-1/-1->7->-1 [15] 6/-1/-1->7->-1 [16] 6/-1/-1->7->-1 [17] 6/-1/-1->7->-1 [18] 6/-1/-1->7->-1 [19] 6/-1/-1->7->-1 [20] 6/-1/-1->7->-1 [21] 6/-1/-1->7->-1 [22] 6/-1/-1->7->-1 [23] 6/-1/-1->7->-1
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Setting affinity for GPU 0 to ffff,0000ffff
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 00/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 01/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 02/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 03/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 04/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 05/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 06/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 07/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 08/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 09/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 10/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 11/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 12/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 13/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 14/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 15/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 16/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 17/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 18/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 19/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 20/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 21/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 22/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 23/24 :    0   7   6   5   4   3   2   1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Trees [0] -1/-1/-1->0->1 [1] -1/-1/-1->0->1 [2] -1/-1/-1->0->1 [3] -1/-1/-1->0->1 [4] -1/-1/-1->0->1 [5] -1/-1/-1->0->1 [6] -1/-1/-1->0->1 [7] -1/-1/-1->0->1 [8] -1/-1/-1->0->1 [9] -1/-1/-1->0->1 [10] -1/-1/-1->0->1 [11] -1/-1/-1->0->1 [12] -1/-1/-1->0->1 [13] -1/-1/-1->0->1 [14] -1/-1/-1->0->1 [15] -1/-1/-1->0->1 [16] -1/-1/-1->0->1 [17] -1/-1/-1->0->1 [18] -1/-1/-1->0->1 [19] -1/-1/-1->0->1 [20] -1/-1/-1->0->1 [21] -1/-1/-1->0->1 [22] -1/-1/-1->0->1 [23] -1/-1/-1->0->1
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Setting affinity for GPU 7 to ffff,0000ffff
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 00 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 00 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 01 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 01 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 00 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 02 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 02 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 01 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 03 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 03 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 02 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 00 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 00 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 04 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 04 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 03 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 01 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 01 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 00 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 05 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 05 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 04 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 02 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 02 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 01 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 06 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 06 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 05 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 03 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 03 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 02 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 07 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 07 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 06 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 04 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 00 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 04 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 03 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 08 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 08 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 07 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 05 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 01 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 05 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 04 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 09 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 09 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 08 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 06 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 02 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 06 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 05 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 10 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 10 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 09 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 07 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 03 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 07 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 06 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 11 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 11 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 10 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 08 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 04 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 08 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 07 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 12 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 12 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 11 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 09 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 05 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 00 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 09 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 08 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 13 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 13 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 12 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 10 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 06 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 01 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 10 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 09 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 14 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 14 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 13 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 11 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 07 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 02 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 11 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 10 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 15 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 15 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 14 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 12 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 08 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 03 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 12 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 11 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 16 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 16 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 15 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 13 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 09 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 04 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 13 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 12 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 17 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 17 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 16 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 14 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 10 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 05 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 14 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 13 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 18 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 18 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 17 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 15 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 11 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 06 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 15 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 14 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 19 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 19 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 18 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 16 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 12 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 07 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 16 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 15 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 20 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 20 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 19 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 17 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 13 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 08 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 17 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 16 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 21 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 21 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 20 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 18 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 14 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 09 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 18 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 17 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 22 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 22 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 21 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 19 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 15 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 10 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 19 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 18 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Channel 23 : 7[100000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 23 : 3[b00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 22 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 20 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 16 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 11 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 20 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 19 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 23 : 1[d00000] -> 0[e00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 21 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 17 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 12 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 21 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 20 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 22 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 18 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 13 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 22 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 21 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 23 : 6[200000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 19 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 14 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 23 : 5[300000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 22 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 20 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 15 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 23 : 2[c00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 21 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 16 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Connected all rings
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 22 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 17 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Connected all rings
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 23 : 4[400000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 18 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 19 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 20 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 21 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 22 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 23 : 0[e00000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Connected all rings
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Connected all rings
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Connected all rings
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Connected all rings
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 00 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 01 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 02 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 03 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 04 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Connected all rings
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 05 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 06 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 07 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 08 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 09 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 10 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 11 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 12 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 13 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 14 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 00 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 15 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 01 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Connected all rings
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 16 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 00 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 02 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 17 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 01 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 03 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 18 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 02 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 04 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 19 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 03 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 05 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 20 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 04 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 06 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 21 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 05 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 07 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 22 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 06 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 08 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 00 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 00 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Channel 23 : 0[e00000] -> 1[d00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 07 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 09 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 01 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 01 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 08 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 10 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 02 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 00 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 02 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 09 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 11 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 03 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 01 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 03 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 10 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 12 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 04 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 02 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 04 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 11 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 13 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 05 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 03 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 05 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 12 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 14 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 06 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 04 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 06 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 13 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 00 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 15 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 07 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 05 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 07 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 14 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 01 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 16 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 08 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 06 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 08 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 15 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 02 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 17 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 09 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 07 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 09 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 16 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 03 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 18 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 10 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 08 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 10 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 17 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 04 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 19 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 11 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 09 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 11 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 18 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 05 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 20 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 12 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 10 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 12 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 19 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 06 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 21 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 13 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 11 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 13 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 20 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 07 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 22 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 14 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 12 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 14 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 21 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 08 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Channel 23 : 6[200000] -> 7[100000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 15 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 13 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 15 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 22 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 09 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 16 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 14 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 16 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Channel 23 : 2[c00000] -> 3[b00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 10 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 17 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 15 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 17 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 11 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 18 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 16 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 18 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 12 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 19 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 17 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 19 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 13 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 20 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 18 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 20 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 14 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 21 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 19 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 21 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 15 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 22 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 20 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 22 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 16 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Channel 23 : 3[b00000] -> 4[400000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 21 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Channel 23 : 4[400000] -> 5[300000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 17 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 22 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO Connected all trees
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 18 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Channel 23 : 1[d00000] -> 2[c00000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 19 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO Connected all trees
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 20 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 21 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO Connected all trees
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO Connected all trees
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 22 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Channel 23 : 5[300000] -> 6[200000] via P2P/direct pointer/read
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO Connected all trees
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO Connected all trees
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO Connected all trees
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO Connected all trees
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
az-wus2-a100-worker-00030:7342:8290 [7] NCCL INFO comm 0x7f99485fddf0 rank 7 nranks 8 cudaDev 7 busId 100000 - Init COMPLETE
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
az-wus2-a100-worker-00030:7342:8286 [3] NCCL INFO comm 0x7f99585fddf0 rank 3 nranks 8 cudaDev 3 busId b00000 - Init COMPLETE
az-wus2-a100-worker-00030:7342:8283 [0] NCCL INFO comm 0x7f99c8008dd0 rank 0 nranks 8 cudaDev 0 busId e00000 - Init COMPLETE
az-wus2-a100-worker-00030:7342:8285 [2] NCCL INFO comm 0x7f99645fddf0 rank 2 nranks 8 cudaDev 2 busId c00000 - Init COMPLETE
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
az-wus2-a100-worker-00030:7342:8288 [5] NCCL INFO comm 0x7f99545fddf0 rank 5 nranks 8 cudaDev 5 busId 300000 - Init COMPLETE
az-wus2-a100-worker-00030:7342:8289 [6] NCCL INFO comm 0x7f99505fddf0 rank 6 nranks 8 cudaDev 6 busId 200000 - Init COMPLETE
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
az-wus2-a100-worker-00030:7342:8287 [4] NCCL INFO comm 0x7f995c5fddf0 rank 4 nranks 8 cudaDev 4 busId 400000 - Init COMPLETE
az-wus2-a100-worker-00030:7342:8284 [1] NCCL INFO comm 0x7f99605fddf0 rank 1 nranks 8 cudaDev 1 busId d00000 - Init COMPLETE
az-wus2-a100-worker-00030:7342:7342 [0] NCCL INFO Launch mode Group/CGMD
using time 181.8648, training loss at epoch 0: 4.9465, cor: 7.987628
+-------+-------------------+--------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time     |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+--------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|   1   | 38.95579242706299 | 38.426130056381226 | 3.7046546936035156 | [0.05856225 0.08932237 0.11209237 0.13016448 0.14576784] | [0.03041571 0.038147   0.04320551 0.04692157 0.049953  ] | [0.00632871 0.00492768 0.0042182  0.0037287  0.0033721 ] | [0.10922072 0.16218781 0.20054965 0.23048264 0.25606664] |
+-------+-------------------+--------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.3876, training loss at epoch 2: 3.2266, cor: 7.069932
using time 38.9456, training loss at epoch 3: 2.9494, cor: 6.666306
using time 38.8242, training loss at epoch 4: 2.7487, cor: 6.326117
using time 38.9166, training loss at epoch 5: 2.6064, cor: 5.994118
using time 38.6963, training loss at epoch 6: 2.4909, cor: 5.603741
using time 38.9709, training loss at epoch 7: 2.3810, cor: 5.323470
using time 39.0124, training loss at epoch 8: 2.3069, cor: 5.124800
+-------+-------------------+-------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |        Loss       |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|   9   | 38.77996468544006 | 39.59576416015625 | 2.233879566192627 | [0.09623974 0.1396049  0.17622905 0.20479244 0.2276417 ] | [0.05192427 0.06298485 0.07119212 0.07713293 0.08165889] | [0.01039722 0.00785086 0.00678368 0.00601334 0.00542024] | [0.17286906 0.24561205 0.30148319 0.34253658 0.37347537] |
+-------+-------------------+-------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.0950, training loss at epoch 10: 2.1711, cor: 4.703175
using time 38.8661, training loss at epoch 11: 2.1135, cor: 4.481674
using time 38.9975, training loss at epoch 12: 2.0585, cor: 4.279203
using time 38.9897, training loss at epoch 13: 2.0171, cor: 4.117356
using time 38.9499, training loss at epoch 14: 1.9682, cor: 3.985025
using time 38.7723, training loss at epoch 15: 1.9381, cor: 3.849742
using time 38.7829, training loss at epoch 16: 1.8951, cor: 3.738915
using time 39.1845, training loss at epoch 17: 1.8628, cor: 3.652916
using time 38.7798, training loss at epoch 18: 1.8247, cor: 3.573603
+-------+-------------------+--------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time     |        Loss       |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+--------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|   19  | 38.95415163040161 | 38.344571113586426 | 1.803531527519226 | [0.11615306 0.16879934 0.20698205 0.23560607 0.25912986] | [0.06230653 0.07575973 0.08431368 0.09030535 0.09497415] | [0.0126383  0.00955079 0.00798615 0.00694281 0.00619357] | [0.20645691 0.28982448 0.34442068 0.38489326 0.41570455] |
+-------+-------------------+--------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 38.9259, training loss at epoch 20: 1.7581, cor: 3.429462
using time 38.8801, training loss at epoch 21: 1.7377, cor: 3.360991
using time 38.7313, training loss at epoch 22: 1.7161, cor: 3.318391
using time 38.8454, training loss at epoch 23: 1.6790, cor: 3.271313
using time 39.1702, training loss at epoch 24: 1.6604, cor: 3.211357
using time 38.7901, training loss at epoch 25: 1.6288, cor: 3.163441
using time 38.7707, training loss at epoch 26: 1.6081, cor: 3.121925
using time 38.7923, training loss at epoch 27: 1.5918, cor: 3.083191
using time 38.8483, training loss at epoch 28: 1.5656, cor: 3.065854
+-------+--------------------+--------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time    |    tesing time     |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+--------------------+--------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|   29  | 38.917473793029785 | 40.845661878585815 | 1.5446850061416626 | [0.12392251 0.17791728 0.2166146  0.24550921 0.26928473] | [0.06623013 0.08006436 0.08872133 0.09478548 0.09950258] | [0.01350101 0.01009513 0.00836367 0.00724685 0.00643963] | [0.21902225 0.30340978 0.35776515 0.39755776 0.42872321] |
+-------+--------------------+--------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 38.7757, training loss at epoch 30: 1.5244, cor: 3.047246
using time 38.9927, training loss at epoch 31: 1.5124, cor: 3.045999
using time 39.0540, training loss at epoch 32: 1.4872, cor: 3.062442
using time 39.0963, training loss at epoch 33: 1.4646, cor: 3.042568
using time 38.7764, training loss at epoch 34: 1.4496, cor: 3.017957
using time 38.8929, training loss at epoch 35: 1.4376, cor: 3.013021
using time 38.9049, training loss at epoch 36: 1.4137, cor: 3.021607
using time 38.7741, training loss at epoch 37: 1.3926, cor: 3.010572
using time 38.9959, training loss at epoch 38: 1.3792, cor: 3.026443
+-------+--------------------+--------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time    |    tesing time     |        Loss       |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+--------------------+--------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|   39  | 38.881675481796265 | 40.010924100875854 | 1.366865634918213 | [0.1294944  0.18511484 0.22354016 0.25346294 0.2781916 ] | [0.06912495 0.08329071 0.09193353 0.09820221 0.10311711] | [0.0141562  0.01048682 0.00864629 0.00748962 0.00666558] | [0.22841439 0.31407687 0.36889972 0.40995311 0.44198269] |
+-------+--------------------+--------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 38.6927, training loss at epoch 40: 1.3490, cor: 3.033722
using time 38.8840, training loss at epoch 41: 1.3340, cor: 3.029233
using time 38.8320, training loss at epoch 42: 1.3122, cor: 3.057854
using time 38.6967, training loss at epoch 43: 1.3002, cor: 3.086934
using time 38.8447, training loss at epoch 44: 1.2860, cor: 3.101903
using time 38.8963, training loss at epoch 45: 1.2683, cor: 3.111048
using time 38.8568, training loss at epoch 46: 1.2549, cor: 3.134888
using time 38.9042, training loss at epoch 47: 1.2395, cor: 3.147783
using time 38.7132, training loss at epoch 48: 1.2260, cor: 3.158187
+-------+-------------------+--------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time     |        Loss       |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+--------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|   49  | 38.80379009246826 | 39.414223432540894 | 1.219747543334961 | [0.13278535 0.18907532 0.22839231 0.25870546 0.2837589 ] | [0.07054391 0.08489781 0.09371816 0.10005476 0.10501809] | [0.01450822 0.01069187 0.00881038 0.00761499 0.00677013] | [0.23369835 0.31958748 0.37558612 0.41658285 0.44869743] |
+-------+-------------------+--------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.0513, training loss at epoch 50: 1.2101, cor: 3.243765
using time 38.9500, training loss at epoch 51: 1.1955, cor: 3.286389
using time 38.8078, training loss at epoch 52: 1.1848, cor: 3.333613
using time 38.7950, training loss at epoch 53: 1.1628, cor: 3.326729
using time 38.7810, training loss at epoch 54: 1.1557, cor: 3.360190
using time 38.8555, training loss at epoch 55: 1.1431, cor: 3.369019
using time 38.8772, training loss at epoch 56: 1.1344, cor: 3.378061
using time 38.8096, training loss at epoch 57: 1.1217, cor: 3.386082
using time 38.7533, training loss at epoch 58: 1.1073, cor: 3.408312
+-------+--------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time    |    tesing time    |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+--------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|   59  | 38.907254457473755 | 38.15647888183594 | 1.1105387210845947 | [0.13351891 0.19147842 0.23080088 0.26102779 0.28709626] | [0.07097838 0.08576804 0.09459759 0.1009308  0.10607346] | [0.01459393 0.0108516  0.00891969 0.007703   0.00685725] | [0.23440665 0.32294485 0.37917015 0.41994022 0.45327308] |
+-------+--------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.3184, training loss at epoch 60: 1.0954, cor: 3.373077
using time 39.3178, training loss at epoch 61: 1.0787, cor: 3.366467
using time 38.8490, training loss at epoch 62: 1.0694, cor: 3.364529
using time 38.9060, training loss at epoch 63: 1.0636, cor: 3.363443
using time 38.8510, training loss at epoch 64: 1.0525, cor: 3.375481
using time 39.0635, training loss at epoch 65: 1.0343, cor: 3.371070
using time 38.9937, training loss at epoch 66: 1.0362, cor: 3.365867
using time 38.9525, training loss at epoch 67: 1.0271, cor: 3.343260
using time 38.9535, training loss at epoch 68: 1.0136, cor: 3.365631
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|   69  | 38.87738847732544 | 38.41511654853821 | 1.0030931234359741 | [0.1345121  0.19198509 0.23142738 0.26174558 0.28778587] | [0.07167639 0.08631146 0.09517192 0.1015059  0.10665094] | [0.01470017 0.01086789 0.00894    0.00771717 0.00687014] | [0.2366024  0.3242198  0.38038843 0.42155516 0.45470386] |
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 38.7241, training loss at epoch 70: 0.9907, cor: 3.357448
using time 38.9616, training loss at epoch 71: 0.9886, cor: 3.365985
using time 38.9097, training loss at epoch 72: 0.9753, cor: 3.399860
using time 38.9379, training loss at epoch 73: 0.9683, cor: 3.413423
using time 39.0059, training loss at epoch 74: 0.9601, cor: 3.432512
using time 38.8173, training loss at epoch 75: 0.9511, cor: 3.435144
using time 38.8573, training loss at epoch 76: 0.9448, cor: 3.449329
using time 38.8341, training loss at epoch 77: 0.9357, cor: 3.440093
using time 38.9369, training loss at epoch 78: 0.9254, cor: 3.422558
+-------+-------------------+--------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time     |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+--------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|   79  | 38.87124490737915 | 38.916682720184326 | 0.9200302958488464 | [0.13607264 0.19471312 0.23364921 0.26419166 0.29040738] | [0.07244416 0.08737266 0.09613679 0.1025502  0.10772321] | [0.01485317 0.01100849 0.00901579 0.00779526 0.00693304] | [0.23889731 0.32737884 0.38343415 0.42498335 0.4578629 ] |
+-------+-------------------+--------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.0508, training loss at epoch 80: 0.9191, cor: 3.401726
using time 38.8370, training loss at epoch 81: 0.9033, cor: 3.385309
using time 38.7845, training loss at epoch 82: 0.8951, cor: 3.382138
using time 38.9050, training loss at epoch 83: 0.8878, cor: 3.378361
using time 38.7954, training loss at epoch 84: 0.8849, cor: 3.369373
using time 38.8334, training loss at epoch 85: 0.8817, cor: 3.333719
using time 39.0547, training loss at epoch 86: 0.8637, cor: 3.319508
using time 38.9625, training loss at epoch 87: 0.8584, cor: 3.308510
using time 38.7619, training loss at epoch 88: 0.8553, cor: 3.293157
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|   89  | 39.00646662712097 | 39.89120626449585 | 0.8451629877090454 | [0.13847527 0.19719201 0.23695861 0.26877602 0.29451244] | [0.07340619 0.08836271 0.09729921 0.103948   0.10906567] | [0.01512799 0.01116608 0.00915745 0.00792523 0.00704282] | [0.24361463 0.33171367 0.38880311 0.43106062 0.46406766] |
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 38.8236, training loss at epoch 90: 0.8401, cor: 3.253402
using time 38.9635, training loss at epoch 91: 0.8355, cor: 3.237755
using time 38.8834, training loss at epoch 92: 0.8255, cor: 3.230994
using time 38.9603, training loss at epoch 93: 0.8191, cor: 3.247255
using time 39.0345, training loss at epoch 94: 0.8138, cor: 3.223984
using time 38.9128, training loss at epoch 95: 0.8065, cor: 3.202487
using time 38.8858, training loss at epoch 96: 0.7974, cor: 3.183049
using time 38.7063, training loss at epoch 97: 0.7958, cor: 3.163985
using time 38.8080, training loss at epoch 98: 0.7890, cor: 3.137870
+-------+-------------------+------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |   tesing time    |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|   99  | 38.78896999359131 | 37.8639280796051 | 0.7776233553886414 | [0.14037228 0.19966161 0.23954433 0.27131097 0.29773236] | [0.07458428 0.08964433 0.09862008 0.10526858 0.11049954] | [0.01531073 0.01125745 0.00922875 0.00798314 0.00709836] | [0.24623536 0.33526937 0.39196215 0.43438965 0.46800584] |
+-------+-------------------+------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 38.8262, training loss at epoch 100: 0.7719, cor: 3.118166
using time 38.8935, training loss at epoch 101: 0.7715, cor: 3.081666
using time 38.8423, training loss at epoch 102: 0.7683, cor: 3.052501
using time 38.9451, training loss at epoch 103: 0.7629, cor: 3.028315
using time 38.8429, training loss at epoch 104: 0.7563, cor: 3.003205
using time 38.8427, training loss at epoch 105: 0.7500, cor: 2.998151
using time 38.8457, training loss at epoch 106: 0.7398, cor: 2.986220
using time 39.1113, training loss at epoch 107: 0.7375, cor: 2.973201
using time 38.7930, training loss at epoch 108: 0.7282, cor: 2.961814
+-------+-------------------+--------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time     |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+--------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  109  | 38.81395411491394 | 39.294907093048096 | 0.7271289229393005 | [0.14126984 0.20095546 0.2413496  0.27359412 0.2996221 ] | [0.07507834 0.09029937 0.09938361 0.10611581 0.11127945] | [0.01540777 0.01135556 0.00930926 0.00804688 0.00714553] | [0.24760947 0.33743678 0.39429956 0.43726537 0.46983326] |
+-------+-------------------+--------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.6441, training loss at epoch 110: 0.7203, cor: 2.897722
using time 38.9235, training loss at epoch 111: 0.7136, cor: 2.906747
using time 38.7870, training loss at epoch 112: 0.7134, cor: 2.886292
using time 38.8980, training loss at epoch 113: 0.7059, cor: 2.850727
using time 39.1662, training loss at epoch 114: 0.7003, cor: 2.830262
using time 38.6903, training loss at epoch 115: 0.6906, cor: 2.803914
using time 38.9627, training loss at epoch 116: 0.6881, cor: 2.771254
using time 38.6749, training loss at epoch 117: 0.6814, cor: 2.770944
using time 38.7277, training loss at epoch 118: 0.6789, cor: 2.773112
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  119  | 38.98486566543579 | 40.75887870788574 | 0.6737518906593323 | [0.14248654 0.20191177 0.24226152 0.27408832 0.30104123] | [0.07585222 0.09100004 0.10006442 0.10671991 0.112057  ] | [0.01553881 0.01140939 0.00933429 0.00806707 0.00718137] | [0.24952189 0.33840008 0.39609865 0.43888031 0.47287898] |
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.0875, training loss at epoch 120: 0.6744, cor: 2.741749
using time 39.1182, training loss at epoch 121: 0.6634, cor: 2.741341
using time 38.9559, training loss at epoch 122: 0.6574, cor: 2.764503
using time 38.9519, training loss at epoch 123: 0.6600, cor: 2.761635
using time 38.7805, training loss at epoch 124: 0.6523, cor: 2.748380
using time 38.8738, training loss at epoch 125: 0.6462, cor: 2.765740
using time 39.0160, training loss at epoch 126: 0.6420, cor: 2.762954
using time 39.0238, training loss at epoch 127: 0.6344, cor: 2.774913
using time 38.7374, training loss at epoch 128: 0.6344, cor: 2.792338
+-------+-------------------+------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |   tesing time    |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  129  | 38.63974618911743 | 39.8015239238739 | 0.6290069818496704 | [0.14429296 0.20476475 0.24589194 0.2782795  0.30508403] | [0.07661815 0.09198439 0.10121168 0.10798533 0.11331184] | [0.01571163 0.01154326 0.00945352 0.00816942 0.00726311] | [0.25231262 0.34246575 0.40094346 0.44354096 0.47779462] |
+-------+-------------------+------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.2008, training loss at epoch 130: 0.6279, cor: 2.777065
using time 38.9470, training loss at epoch 131: 0.6213, cor: 2.801107
using time 38.8492, training loss at epoch 132: 0.6195, cor: 2.794793
using time 39.1127, training loss at epoch 133: 0.6096, cor: 2.778923
using time 38.9024, training loss at epoch 134: 0.6030, cor: 2.784095
using time 39.1156, training loss at epoch 135: 0.6086, cor: 2.762815
using time 39.1486, training loss at epoch 136: 0.6028, cor: 2.765912
using time 38.9790, training loss at epoch 137: 0.5964, cor: 2.764284
using time 38.9036, training loss at epoch 138: 0.5939, cor: 2.766536
+-------+------------------+--------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |  training time   |    tesing time     |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+------------------+--------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  139  | 38.9142644405365 | 39.099467515945435 | 0.5865402817726135 | [0.14558839 0.20660871 0.24780823 0.27999167 0.30720412] | [0.07729416 0.09280385 0.10204172 0.10878886 0.11418293] | [0.01580655 0.01160736 0.009492   0.00819651 0.00729059] | [0.25397005 0.34476066 0.40328087 0.44565171 0.47990537] |
+-------+------------------+--------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 38.8089, training loss at epoch 140: 0.5835, cor: 2.772901
using time 38.9499, training loss at epoch 141: 0.5802, cor: 2.805954
using time 38.8037, training loss at epoch 142: 0.5771, cor: 2.793237
using time 38.9649, training loss at epoch 143: 0.5727, cor: 2.853310
using time 38.9831, training loss at epoch 144: 0.5694, cor: 2.831607
using time 38.8786, training loss at epoch 145: 0.5662, cor: 2.924699
using time 38.7658, training loss at epoch 146: 0.5592, cor: 2.969418
using time 38.9066, training loss at epoch 147: 0.5590, cor: 2.923132
using time 38.7678, training loss at epoch 148: 0.5561, cor: 2.882379
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  149  | 38.75114059448242 | 39.73864221572876 | 0.5549457669258118 | [0.14739223 0.20714586 0.24929504 0.28144418 0.30863388] | [0.0782438  0.09347391 0.10293736 0.10966295 0.11505556] | [0.01593758 0.01162613 0.00955339 0.00824007 0.00732643] | [0.25667578 0.34600728 0.40546245 0.44831494 0.4824836 ] |
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 38.9808, training loss at epoch 150: 0.5499, cor: 2.871360
using time 38.7344, training loss at epoch 151: 0.5472, cor: 2.871741
using time 38.8196, training loss at epoch 152: 0.5401, cor: 2.856069
using time 38.8568, training loss at epoch 153: 0.5428, cor: 2.869997
using time 39.1087, training loss at epoch 154: 0.5320, cor: 2.878210
using time 38.8381, training loss at epoch 155: 0.5350, cor: 2.902887
using time 38.9791, training loss at epoch 156: 0.5289, cor: 2.899582
using time 39.0767, training loss at epoch 157: 0.5272, cor: 2.908696
using time 38.9024, training loss at epoch 158: 0.5239, cor: 2.912894
+-------+--------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time    |    tesing time    |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+--------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  159  | 38.961854457855225 | 40.64367389678955 | 0.5218572020530701 | [0.14838492 0.21047501 0.25277918 0.28521637 0.31280561] | [0.07867674 0.09444229 0.10395313 0.11076239 0.11623678] | [0.01605587 0.01178443 0.00967239 0.00834738 0.00742446] | [0.25819155 0.3505121  0.41013727 0.45262144 0.48714425] |
+-------+--------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 38.9445, training loss at epoch 160: 0.5126, cor: 2.899575
using time 38.9032, training loss at epoch 161: 0.5147, cor: 2.902030
using time 39.4554, training loss at epoch 162: 0.5094, cor: 2.897736
using time 39.3528, training loss at epoch 163: 0.5078, cor: 2.928462
using time 39.1501, training loss at epoch 164: 0.5010, cor: 2.944820
using time 39.0287, training loss at epoch 165: 0.4974, cor: 2.949957
using time 39.0159, training loss at epoch 166: 0.4966, cor: 2.992895
using time 38.9800, training loss at epoch 167: 0.4916, cor: 2.966970
using time 38.8280, training loss at epoch 168: 0.4888, cor: 2.927374
+-------+--------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time    |    tesing time     |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+--------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  169  | 38.938700675964355 | 39.917051792144775 | 0.48815247416496277 | [0.1485666  0.21048769 0.25245552 0.2857703  0.31282413] | [0.07883909 0.09458649 0.10404795 0.11101195 0.11636753] | [0.01607854 0.0117855  0.00967522 0.00836296 0.00741539] | [0.25878653 0.35066793 0.40894732 0.45252228 0.48581264] |
+-------+--------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.1221, training loss at epoch 170: 0.4823, cor: 2.977793
using time 38.9874, training loss at epoch 171: 0.4789, cor: 2.963002
using time 38.8702, training loss at epoch 172: 0.4786, cor: 2.956479
using time 38.8608, training loss at epoch 173: 0.4776, cor: 2.987882
using time 38.9485, training loss at epoch 174: 0.4721, cor: 2.979706
using time 38.8526, training loss at epoch 175: 0.4715, cor: 2.970373
using time 38.8635, training loss at epoch 176: 0.4680, cor: 3.004828
using time 38.9440, training loss at epoch 177: 0.4655, cor: 2.990093
using time 39.1760, training loss at epoch 178: 0.4626, cor: 3.036839
+-------+-------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time     |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  179  | 38.90393304824829 | 41.375826597213745 | 0.46071866154670715 | [0.15086846 0.21271227 0.25506288 0.28808927 0.31572635] | [0.08049612 0.09625085 0.10577427 0.11268483 0.11817439] | [0.01631865 0.01192078 0.00976824 0.00842441 0.00748948] | [0.26254055 0.3539828  0.4128855  0.45572382 0.49007664] |
+-------+-------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.0358, training loss at epoch 180: 0.4533, cor: 3.038094
using time 39.0088, training loss at epoch 181: 0.4536, cor: 3.036609
using time 39.1345, training loss at epoch 182: 0.4557, cor: 3.049450
using time 39.5533, training loss at epoch 183: 0.4519, cor: 3.090637
using time 39.2917, training loss at epoch 184: 0.4479, cor: 3.075136
using time 39.3668, training loss at epoch 185: 0.4394, cor: 3.060832
using time 39.4748, training loss at epoch 186: 0.4391, cor: 3.082700
using time 39.4902, training loss at epoch 187: 0.4396, cor: 3.081019
using time 39.5309, training loss at epoch 188: 0.4385, cor: 3.128117
+-------+-------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time     |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  189  | 39.37465786933899 | 38.839962005615234 | 0.43525853753089905 | [0.15071886 0.21271197 0.25519588 0.28872632 0.31568355] | [0.0803742  0.09616153 0.10572172 0.11271861 0.11807704] | [0.0162712  0.01189068 0.00975053 0.00842175 0.00747078] | [0.26180391 0.35386947 0.41231885 0.45568132 0.48878752] |
+-------+-------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 40.2945, training loss at epoch 190: 0.4301, cor: 3.120472
using time 39.5267, training loss at epoch 191: 0.4310, cor: 3.129066
using time 39.1547, training loss at epoch 192: 0.4293, cor: 3.120662
using time 39.2395, training loss at epoch 193: 0.4246, cor: 3.135716
using time 39.4320, training loss at epoch 194: 0.4218, cor: 3.182248
using time 39.4975, training loss at epoch 195: 0.4169, cor: 3.151556
using time 39.3479, training loss at epoch 196: 0.4204, cor: 3.193895
using time 39.4078, training loss at epoch 197: 0.4174, cor: 3.211319
using time 39.4670, training loss at epoch 198: 0.4108, cor: 3.213360
+-------+--------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time    |    tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+--------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  199  | 39.514206409454346 | 39.64070463180542 | 0.41432857513427734 | [0.15078066 0.21346985 0.25626186 0.28912495 0.31595464] | [0.08042884 0.09638047 0.10603268 0.11291281 0.11825069] | [0.01626482 0.01192432 0.00979894 0.00844637 0.00749217] | [0.26164809 0.35507359 0.41374963 0.45630463 0.4902608 ] |
+-------+--------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.8223, training loss at epoch 200: 0.4087, cor: 3.264201
using time 39.6217, training loss at epoch 201: 0.4036, cor: 3.263544
using time 39.3723, training loss at epoch 202: 0.4049, cor: 3.244687
using time 39.6496, training loss at epoch 203: 0.3999, cor: 3.233962
using time 39.6896, training loss at epoch 204: 0.3982, cor: 3.243719
using time 39.2278, training loss at epoch 205: 0.3964, cor: 3.269838
using time 39.5480, training loss at epoch 206: 0.3962, cor: 3.246669
using time 40.0020, training loss at epoch 207: 0.3946, cor: 3.220428
using time 39.2261, training loss at epoch 208: 0.3940, cor: 3.213825
+-------+--------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time    |    tesing time    |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+--------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  209  | 39.346670389175415 | 37.61405634880066 | 0.3892422914505005 | [0.15139119 0.21391302 0.25672073 0.28935123 0.31647942] | [0.08071125 0.09664423 0.10626467 0.11311295 0.11849114] | [0.01629882 0.01193637 0.00979138 0.0084384  0.00748212] | [0.26248389 0.35474777 0.41394795 0.45655962 0.49007664] |
+-------+--------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.5430, training loss at epoch 210: 0.3898, cor: 3.236963
using time 39.4600, training loss at epoch 211: 0.3857, cor: 3.257377
using time 39.9878, training loss at epoch 212: 0.3800, cor: 3.270759
using time 38.8389, training loss at epoch 213: 0.3827, cor: 3.273366
using time 38.9714, training loss at epoch 214: 0.3771, cor: 3.217293
using time 38.7797, training loss at epoch 215: 0.3726, cor: 3.256558
using time 38.8665, training loss at epoch 216: 0.3752, cor: 3.318644
using time 38.7364, training loss at epoch 217: 0.3772, cor: 3.283517
using time 38.8152, training loss at epoch 218: 0.3732, cor: 3.224555
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  219  | 38.63254952430725 | 38.45995759963989 | 0.37042006850242615 | [0.15327605 0.21552004 0.25882304 0.29168055 0.31917726] | [0.08154329 0.09740184 0.10716063 0.11401823 0.11949839] | [0.01649219 0.0120242  0.00988134 0.00849542 0.00755125] | [0.26494879 0.35785015 0.4179428  0.459577   0.49381649] |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.1114, training loss at epoch 220: 0.3713, cor: 3.309510
using time 38.9837, training loss at epoch 221: 0.3650, cor: 3.300025
using time 39.1008, training loss at epoch 222: 0.3648, cor: 3.302765
using time 38.9811, training loss at epoch 223: 0.3649, cor: 3.306787
using time 38.8498, training loss at epoch 224: 0.3570, cor: 3.301903
using time 39.0803, training loss at epoch 225: 0.3588, cor: 3.294675
using time 38.8134, training loss at epoch 226: 0.3552, cor: 3.294201
using time 39.0374, training loss at epoch 227: 0.3556, cor: 3.301197
using time 38.7650, training loss at epoch 228: 0.3548, cor: 3.285634
+-------+-------------------+------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |   tesing time    |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  229  | 38.93556046485901 | 39.0514132976532 | 0.3527665138244629 | [0.15368975 0.2165695  0.26012202 0.29355809 0.32119776] | [0.08190376 0.09796803 0.10775438 0.11474361 0.12021689] | [0.01648935 0.01208865 0.00992407 0.0085496  0.00758298] | [0.26543044 0.35915343 0.41884943 0.46202774 0.49594141] |
+-------+-------------------+------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.2157, training loss at epoch 230: 0.3526, cor: 3.313393
using time 38.8294, training loss at epoch 231: 0.3477, cor: 3.317360
using time 38.7261, training loss at epoch 232: 0.3447, cor: 3.336508
using time 38.8596, training loss at epoch 233: 0.3423, cor: 3.477294
using time 38.7123, training loss at epoch 234: 0.3408, cor: 3.580489
using time 38.9592, training loss at epoch 235: 0.3415, cor: 3.467561
using time 38.8592, training loss at epoch 236: 0.3404, cor: 3.402807
using time 38.8951, training loss at epoch 237: 0.3394, cor: 3.353512
using time 38.6307, training loss at epoch 238: 0.3411, cor: 3.365658
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  239  | 38.90446734428406 | 39.34260821342468 | 0.3375454843044281 | [0.15361342 0.2171539  0.26004593 0.29290437 0.32102476] | [0.08180681 0.09799878 0.10767051 0.11454212 0.12010024] | [0.0165021  0.0121138  0.0099236  0.00854022 0.00758482] | [0.26524628 0.36014506 0.41879276 0.4611636  0.49633806] |
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.3505, training loss at epoch 240: 0.3308, cor: 3.396835
using time 38.9691, training loss at epoch 241: 0.3311, cor: 3.406475
using time 38.7768, training loss at epoch 242: 0.3274, cor: 3.400392
using time 38.8918, training loss at epoch 243: 0.3320, cor: 3.378417
using time 39.1455, training loss at epoch 244: 0.3256, cor: 3.350359
using time 39.1500, training loss at epoch 245: 0.3257, cor: 3.338452
using time 39.1699, training loss at epoch 246: 0.3230, cor: 3.335733
using time 38.8363, training loss at epoch 247: 0.3235, cor: 3.346005
using time 38.8664, training loss at epoch 248: 0.3222, cor: 3.339033
+-------+--------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time    |    tesing time     |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+--------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  249  | 38.926897287368774 | 39.381306409835815 | 0.31945574283599854 | [0.15438957 0.21757678 0.26071282 0.29369242 0.32109745] | [0.08230054 0.09841708 0.10813387 0.11502884 0.12045913] | [0.0165616  0.01212655 0.00993847 0.00854642 0.00757731] | [0.2656571  0.36006006 0.41947274 0.46236772 0.49643722] |
+-------+--------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.0595, training loss at epoch 250: 0.3170, cor: 3.334026
using time 38.8207, training loss at epoch 251: 0.3143, cor: 3.328518
using time 38.9232, training loss at epoch 252: 0.3118, cor: 3.414036
using time 39.0949, training loss at epoch 253: 0.3153, cor: 3.361872
using time 39.0376, training loss at epoch 254: 0.3110, cor: 3.359320
using time 38.7207, training loss at epoch 255: 0.3112, cor: 3.359163
using time 38.7291, training loss at epoch 256: 0.3113, cor: 3.357166
using time 38.8204, training loss at epoch 257: 0.3080, cor: 3.348800
using time 38.9566, training loss at epoch 258: 0.3028, cor: 3.348932
+-------+-------------------+--------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time     |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+--------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  259  | 38.98552751541138 | 40.108452796936035 | 0.3070024847984314 | [0.15618425 0.2195299  0.26262257 0.29611387 0.32329393] | [0.08348779 0.09964814 0.1093595  0.11634512 0.12175329] | [0.01678684 0.0122544  0.01003386 0.00862946 0.00764616] | [0.26901446 0.36280829 0.42141349 0.46481846 0.49880296] |
+-------+-------------------+--------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.0507, training loss at epoch 260: 0.3031, cor: 3.331301
using time 38.9999, training loss at epoch 261: 0.3031, cor: 3.347026
using time 38.9880, training loss at epoch 262: 0.3000, cor: 3.357507
using time 39.0032, training loss at epoch 263: 0.2989, cor: 3.360420
using time 38.8467, training loss at epoch 264: 0.2977, cor: 3.376900
using time 38.9400, training loss at epoch 265: 0.2969, cor: 3.365969
using time 38.8404, training loss at epoch 266: 0.2962, cor: 3.366963
using time 38.8120, training loss at epoch 267: 0.2973, cor: 3.385322
using time 38.9674, training loss at epoch 268: 0.2883, cor: 3.397836
+-------+--------------------+--------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time    |    tesing time     |        Loss       |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+--------------------+--------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  269  | 39.105952978134155 | 39.230159282684326 | 0.289675235748291 | [0.15540051 0.21871897 0.26256683 0.29589531 0.32251298] | [0.08308365 0.09920945 0.10909633 0.1160663  0.12135913] | [0.01669122 0.01218356 0.01001025 0.00862114 0.00762307] | [0.26802284 0.36221331 0.42193764 0.46420932 0.49730136] |
+-------+--------------------+--------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.2530, training loss at epoch 270: 0.2871, cor: 3.378614
using time 38.9830, training loss at epoch 271: 0.2890, cor: 3.347556
using time 39.0661, training loss at epoch 272: 0.2858, cor: 3.380766
using time 38.8473, training loss at epoch 273: 0.2886, cor: 3.357382
using time 38.8995, training loss at epoch 274: 0.2826, cor: 3.387525
using time 38.8898, training loss at epoch 275: 0.2831, cor: 3.372755
using time 38.8771, training loss at epoch 276: 0.2825, cor: 3.351748
using time 38.8347, training loss at epoch 277: 0.2804, cor: 3.320715
using time 38.9982, training loss at epoch 278: 0.2799, cor: 3.338007
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  279  | 38.80781841278076 | 38.67039489746094 | 0.2807180881500244 | [0.1557433  0.2196387  0.26264561 0.29590522 0.32335893] | [0.08317758 0.09946934 0.10916496 0.11611903 0.12156222] | [0.01670539 0.01224165 0.01001214 0.00861795 0.00763483] | [0.26742786 0.36311994 0.42151266 0.46423765 0.49815132] |
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.6546, training loss at epoch 280: 0.2780, cor: 3.395846
using time 38.7386, training loss at epoch 281: 0.2758, cor: 3.354568
using time 38.8068, training loss at epoch 282: 0.2765, cor: 3.376294
using time 38.9460, training loss at epoch 283: 0.2709, cor: 3.380899
using time 38.8552, training loss at epoch 284: 0.2738, cor: 3.333452
using time 38.7493, training loss at epoch 285: 0.2739, cor: 3.337988
using time 38.7020, training loss at epoch 286: 0.2708, cor: 3.338238
using time 38.8007, training loss at epoch 287: 0.2713, cor: 3.396329
using time 39.1051, training loss at epoch 288: 0.2706, cor: 3.352963
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  289  | 40.50627779960632 | 38.05064535140991 | 0.26413124799728394 | [0.15666665 0.22080656 0.26376168 0.29786903 0.3248599 ] | [0.08367623 0.10003353 0.10969544 0.11680258 0.12217527] | [0.01676418 0.01227954 0.01003008 0.00864204 0.00765027] | [0.2689153  0.36470655 0.42290094 0.46605091 0.49955377] |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.0689, training loss at epoch 290: 0.2651, cor: 3.351842
using time 38.9327, training loss at epoch 291: 0.2641, cor: 3.335529
using time 38.7352, training loss at epoch 292: 0.2652, cor: 3.337124
using time 38.8817, training loss at epoch 293: 0.2615, cor: 3.334058
using time 38.7917, training loss at epoch 294: 0.2662, cor: 3.325183
using time 39.0235, training loss at epoch 295: 0.2613, cor: 3.351560
using time 38.6725, training loss at epoch 296: 0.2583, cor: 3.326639
using time 38.8781, training loss at epoch 297: 0.2556, cor: 3.296128
using time 38.8870, training loss at epoch 298: 0.2524, cor: 3.321422
+-------+-------------------+-----------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |   tesing time   |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-----------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  299  | 39.07647228240967 | 40.910076379776 | 0.2567598223686218 | [0.15719076 0.22070063 0.26352143 0.29730497 0.32484769] | [0.08383527 0.10004525 0.10968995 0.11672161 0.12219005] | [0.01681872 0.0122845  0.01002772 0.00862521 0.00764304] | [0.27013359 0.36402658 0.4230001  0.4655126  0.50030457] |
+-------+-------------------+-----------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.0646, training loss at epoch 300: 0.2529, cor: 3.351729
using time 39.1050, training loss at epoch 301: 0.2514, cor: 3.307678
using time 38.8804, training loss at epoch 302: 0.2530, cor: 3.301071
using time 38.8060, training loss at epoch 303: 0.2498, cor: 3.285484
using time 38.9303, training loss at epoch 304: 0.2519, cor: 3.289863
using time 39.0159, training loss at epoch 305: 0.2454, cor: 3.310683
using time 38.9397, training loss at epoch 306: 0.2458, cor: 3.305171
using time 38.8450, training loss at epoch 307: 0.2457, cor: 3.296252
using time 38.9024, training loss at epoch 308: 0.2453, cor: 3.296195
+-------+--------------------+-------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time    |    tesing time    |        Loss       |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+--------------------+-------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  309  | 39.009753704071045 | 38.09442949295044 | 0.245313361287117 | [0.15689002 0.22058498 0.26396459 0.29774913 0.32529878] | [0.08351451 0.09975906 0.10951589 0.1165691  0.12202332] | [0.01674576 0.01224731 0.010023   0.00863088 0.00764446] | [0.26880197 0.36404074 0.42263178 0.46571093 0.50010625] |
+-------+--------------------+-------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.5482, training loss at epoch 310: 0.2436, cor: 3.246840
using time 38.9185, training loss at epoch 311: 0.2437, cor: 3.265747
using time 38.9574, training loss at epoch 312: 0.2427, cor: 3.262548
using time 38.9491, training loss at epoch 313: 0.2413, cor: 3.304819
using time 38.9238, training loss at epoch 314: 0.2398, cor: 3.309018
using time 38.8348, training loss at epoch 315: 0.2373, cor: 3.264892
using time 39.0070, training loss at epoch 316: 0.2380, cor: 3.305264
using time 38.9876, training loss at epoch 317: 0.2355, cor: 3.270880
using time 38.9772, training loss at epoch 318: 0.2386, cor: 3.337377
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  319  | 38.85560345649719 | 40.25102090835571 | 0.23351822793483734 | [0.15751809 0.22051077 0.26416605 0.2977614  0.32504274] | [0.08392853 0.10001896 0.10982625 0.11680827 0.1222299 ] | [0.01686759 0.01227848 0.0100459  0.00862663 0.00763922] | [0.27026108 0.36432406 0.42314176 0.46668839 0.49983709] |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 38.9164, training loss at epoch 320: 0.2316, cor: 3.367457
using time 38.9678, training loss at epoch 321: 0.2315, cor: 3.343703
using time 39.1218, training loss at epoch 322: 0.2293, cor: 3.269085
using time 38.8143, training loss at epoch 323: 0.2301, cor: 3.262465
using time 38.8042, training loss at epoch 324: 0.2301, cor: 3.269369
using time 39.0893, training loss at epoch 325: 0.2329, cor: 3.269754
using time 38.8536, training loss at epoch 326: 0.2287, cor: 3.301284
using time 38.7008, training loss at epoch 327: 0.2285, cor: 3.263140
using time 38.8228, training loss at epoch 328: 0.2266, cor: 3.262495
+-------+------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |  training time   |    tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  329  | 38.8627188205719 | 39.94525408744812 | 0.22544744610786438 | [0.15902101 0.22225363 0.26593987 0.29939807 0.3263629 ] | [0.08504073 0.10115746 0.11099204 0.11797031 0.12333533] | [0.01700642 0.0123277  0.01009265 0.00866665 0.00767095] | [0.27278265 0.36643481 0.42596082 0.46864331 0.50172118] |
+-------+------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 38.8170, training loss at epoch 330: 0.2246, cor: 3.249646
using time 38.8658, training loss at epoch 331: 0.2241, cor: 3.242311
using time 38.8597, training loss at epoch 332: 0.2215, cor: 3.246055
using time 38.8608, training loss at epoch 333: 0.2220, cor: 3.203902
using time 38.8625, training loss at epoch 334: 0.2211, cor: 3.264520
using time 38.9652, training loss at epoch 335: 0.2217, cor: 3.259994
using time 38.7769, training loss at epoch 336: 0.2197, cor: 3.224601
using time 38.8145, training loss at epoch 337: 0.2174, cor: 3.209072
using time 38.9434, training loss at epoch 338: 0.2173, cor: 3.211947
+-------+-------------------+--------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time     |        Loss       |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+--------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  339  | 38.91220259666443 | 39.872055530548096 | 0.220049649477005 | [0.16011805 0.22468194 0.26783806 0.3014128  0.32917596] | [0.08576569 0.10222006 0.11194171 0.11893511 0.12444852] | [0.01708221 0.01244174 0.01015285 0.00871358 0.00772365] | [0.27377428 0.36882889 0.42834072 0.47075406 0.50439858] |
+-------+-------------------+--------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.0130, training loss at epoch 340: 0.2180, cor: 3.216928
using time 39.0572, training loss at epoch 341: 0.2158, cor: 3.198512
using time 38.9328, training loss at epoch 342: 0.2171, cor: 3.256900
using time 38.7583, training loss at epoch 343: 0.2151, cor: 3.238715
using time 38.8709, training loss at epoch 344: 0.2141, cor: 3.236090
using time 38.9668, training loss at epoch 345: 0.2117, cor: 3.259621
using time 39.1356, training loss at epoch 346: 0.2093, cor: 3.247255
using time 39.0154, training loss at epoch 347: 0.2111, cor: 3.230029
using time 38.9494, training loss at epoch 348: 0.2083, cor: 3.211877
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  349  | 38.94495224952698 | 39.85595417022705 | 0.2115386724472046 | [0.15939841 0.2226066  0.26602938 0.29966725 0.32686795] | [0.08528414 0.10140595 0.1111878  0.11820102 0.12358918] | [0.01699863 0.01232948 0.01007801 0.00866169 0.00766486] | [0.27319347 0.36608066 0.42591832 0.46855831 0.50186284] |
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.6194, training loss at epoch 350: 0.2065, cor: 3.267581
using time 39.0690, training loss at epoch 351: 0.2094, cor: 3.265636
using time 39.4342, training loss at epoch 352: 0.2086, cor: 3.295880
using time 38.7599, training loss at epoch 353: 0.2077, cor: 3.301050
using time 39.0067, training loss at epoch 354: 0.2092, cor: 3.242965
using time 39.1738, training loss at epoch 355: 0.2047, cor: 3.207770
using time 38.8439, training loss at epoch 356: 0.2039, cor: 3.212349
using time 38.8020, training loss at epoch 357: 0.2003, cor: 3.212399
using time 39.0563, training loss at epoch 358: 0.2011, cor: 3.197551
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  359  | 39.03625798225403 | 41.63121008872986 | 0.20039305090904236 | [0.16017263 0.2239458  0.26717195 0.30107623 0.32896399] | [0.08583198 0.10212887 0.11187898 0.11893189 0.12445432] | [0.01706875 0.01241908 0.01014388 0.00871853 0.00772379] | [0.27412843 0.36833307 0.42737743 0.47103738 0.50489439] |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 38.9331, training loss at epoch 360: 0.2000, cor: 3.201955
using time 38.9772, training loss at epoch 361: 0.2024, cor: 3.254233
using time 38.8796, training loss at epoch 362: 0.2011, cor: 3.230821
using time 38.8560, training loss at epoch 363: 0.1974, cor: 3.222910
using time 38.8995, training loss at epoch 364: 0.1976, cor: 3.197168
using time 38.8101, training loss at epoch 365: 0.1974, cor: 3.193188
using time 39.2431, training loss at epoch 366: 0.1955, cor: 3.221501
using time 39.1362, training loss at epoch 367: 0.1959, cor: 3.200201
using time 38.8233, training loss at epoch 368: 0.1936, cor: 3.272773
+-------+-------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time     |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  369  | 38.81409788131714 | 40.354753494262695 | 0.19364918768405914 | [0.15978953 0.22403328 0.26686891 0.30036034 0.32720562] | [0.08558226 0.10196822 0.11162841 0.11860795 0.12393562] | [0.01707583 0.01243395 0.01013798 0.00869782 0.00768512] | [0.27376011 0.36837557 0.42661246 0.46920996 0.50286864] |
+-------+-------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.6209, training loss at epoch 370: 0.1932, cor: 3.199252
using time 38.9028, training loss at epoch 371: 0.1933, cor: 3.263414
using time 39.0528, training loss at epoch 372: 0.1942, cor: 3.240751
using time 38.9167, training loss at epoch 373: 0.1933, cor: 3.213202
using time 38.9411, training loss at epoch 374: 0.1885, cor: 3.195717
using time 38.8052, training loss at epoch 375: 0.1874, cor: 3.219189
using time 38.9008, training loss at epoch 376: 0.1886, cor: 3.210768
using time 38.8166, training loss at epoch 377: 0.1855, cor: 3.177212
using time 38.7697, training loss at epoch 378: 0.1848, cor: 3.200880
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  379  | 39.07114100456238 | 38.46485257148743 | 0.18820179998874664 | [0.1605751  0.22438583 0.26701747 0.30070284 0.32774578] | [0.08579996 0.10208792 0.11168118 0.11871858 0.12408556] | [0.01708221 0.01242333 0.01010398 0.00868843 0.00767917] | [0.27412843 0.36775226 0.42700911 0.4698616  0.50248615] |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 38.9579, training loss at epoch 380: 0.1841, cor: 3.212218
using time 38.9953, training loss at epoch 381: 0.1866, cor: 3.181484
using time 38.7796, training loss at epoch 382: 0.1878, cor: 3.176566
using time 38.8812, training loss at epoch 383: 0.1835, cor: 3.187688
using time 38.8629, training loss at epoch 384: 0.1834, cor: 3.194487
using time 38.9279, training loss at epoch 385: 0.1831, cor: 3.419315
using time 38.8154, training loss at epoch 386: 0.1809, cor: 3.503256
using time 39.0691, training loss at epoch 387: 0.1814, cor: 3.394675
using time 38.8103, training loss at epoch 388: 0.1836, cor: 3.303790
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  389  | 38.73970127105713 | 40.70049500465393 | 0.18187986314296722 | [0.16147786 0.22539953 0.26787799 0.30124294 0.32818299] | [0.08619396 0.1025362  0.11213063 0.11908781 0.12443967] | [0.01717712 0.01249947 0.01016985 0.0087196  0.00770226] | [0.2757292  0.36963636 0.4280999  0.47062657 0.5037186 ] |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.0171, training loss at epoch 390: 0.1798, cor: 3.204302
using time 38.9003, training loss at epoch 391: 0.1799, cor: 3.191422
using time 38.9347, training loss at epoch 392: 0.1797, cor: 3.184862
using time 38.9425, training loss at epoch 393: 0.1780, cor: 3.173895
using time 38.9942, training loss at epoch 394: 0.1796, cor: 3.176147
using time 38.6959, training loss at epoch 395: 0.1771, cor: 3.161896
using time 38.8475, training loss at epoch 396: 0.1769, cor: 3.170982
using time 38.9493, training loss at epoch 397: 0.1806, cor: 3.148000
using time 38.7741, training loss at epoch 398: 0.1756, cor: 3.166090
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  399  | 38.75336766242981 | 38.66249108314514 | 0.17463544011116028 | [0.16164344 0.2249192  0.26763536 0.30145659 0.32855944] | [0.08641072 0.10261544 0.11221941 0.11926657 0.12464979] | [0.01718279 0.01246228 0.01013349 0.00870437 0.00769758] | [0.27582836 0.3685314  0.42716494 0.47035741 0.50322279] |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.1956, training loss at epoch 400: 0.1767, cor: 3.187586
using time 39.1125, training loss at epoch 401: 0.1734, cor: 3.152991
using time 38.9302, training loss at epoch 402: 0.1732, cor: 3.157047
using time 39.0904, training loss at epoch 403: 0.1733, cor: 3.167701
using time 38.7760, training loss at epoch 404: 0.1723, cor: 3.176835
using time 39.1898, training loss at epoch 405: 0.1721, cor: 3.147986
using time 38.9626, training loss at epoch 406: 0.1683, cor: 3.129551
using time 38.8634, training loss at epoch 407: 0.1702, cor: 3.140911
using time 38.9165, training loss at epoch 408: 0.1709, cor: 3.137267
+-------+--------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time    |    tesing time     |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+--------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  409  | 38.933586835861206 | 40.252496004104614 | 0.17084193229675293 | [0.1617229  0.2245398  0.26709962 0.30074651 0.32811282] | [0.08641902 0.10244391 0.11204605 0.11906455 0.12447518] | [0.01717429 0.01239924 0.01010044 0.00868064 0.00767222] | [0.27640917 0.36816308 0.42686745 0.46983326 0.50278364] |
+-------+--------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.0182, training loss at epoch 410: 0.1672, cor: 3.124438
using time 39.0241, training loss at epoch 411: 0.1651, cor: 3.154496
using time 38.9601, training loss at epoch 412: 0.1678, cor: 3.160745
using time 38.9436, training loss at epoch 413: 0.1675, cor: 3.125735
using time 38.8115, training loss at epoch 414: 0.1647, cor: 3.160057
using time 38.9530, training loss at epoch 415: 0.1648, cor: 3.164652
using time 39.0388, training loss at epoch 416: 0.1631, cor: 3.171991
using time 39.0288, training loss at epoch 417: 0.1639, cor: 3.162528
using time 38.8183, training loss at epoch 418: 0.1613, cor: 3.129682
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  419  | 38.74083638191223 | 39.97656607627869 | 0.1660938411951065 | [0.16170374 0.22518836 0.26796882 0.30176818 0.32968333] | [0.08659811 0.10281834 0.1124604  0.11950561 0.12504252] | [0.01718633 0.0124683  0.01015262 0.00872243 0.00773271] | [0.27589919 0.36963636 0.42812823 0.47109405 0.50466773] |
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.4716, training loss at epoch 420: 0.1607, cor: 3.131420
using time 38.9952, training loss at epoch 421: 0.1607, cor: 3.155998
using time 39.1554, training loss at epoch 422: 0.1620, cor: 3.152028
using time 39.0097, training loss at epoch 423: 0.1599, cor: 3.101880
using time 38.9366, training loss at epoch 424: 0.1595, cor: 3.132116
using time 39.1993, training loss at epoch 425: 0.1615, cor: 3.110844
using time 39.0762, training loss at epoch 426: 0.1609, cor: 3.128927
using time 39.0526, training loss at epoch 427: 0.1576, cor: 3.129307
using time 39.1094, training loss at epoch 428: 0.1584, cor: 3.175438
+-------+-------------------+------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |   tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  429  | 39.09138488769531 | 39.2841579914093 | 0.15842194855213165 | [0.16196516 0.2255835  0.26802906 0.30181373 0.32953361] | [0.08674057 0.1030079  0.11257886 0.11964923 0.12511993] | [0.01720191 0.01247362 0.01014601 0.00873128 0.00771982] | [0.27635251 0.36979218 0.4281849  0.47150487 0.50461107] |
+-------+-------------------+------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.0298, training loss at epoch 430: 0.1574, cor: 3.130391
using time 38.9002, training loss at epoch 431: 0.1559, cor: 3.137319
using time 38.8895, training loss at epoch 432: 0.1568, cor: 3.135285
using time 39.1628, training loss at epoch 433: 0.1543, cor: 3.178149
using time 38.9991, training loss at epoch 434: 0.1577, cor: 3.124027
using time 38.7421, training loss at epoch 435: 0.1561, cor: 3.109823
using time 39.0800, training loss at epoch 436: 0.1542, cor: 3.152303
using time 39.2135, training loss at epoch 437: 0.1537, cor: 3.136359
using time 38.8923, training loss at epoch 438: 0.1545, cor: 3.085409
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  439  | 38.97907996177673 | 38.75495743751526 | 0.15273702144622803 | [0.16165449 0.2258077  0.26815241 0.30171036 0.32990415] | [0.08647018 0.10284067 0.1123867  0.11942483 0.12498625] | [0.01719412 0.01248141 0.01014766 0.00872792 0.0077279 ] | [0.27618252 0.37048632 0.42856738 0.47147653 0.50534771] |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.4792, training loss at epoch 440: 0.1507, cor: 3.104465
using time 39.0259, training loss at epoch 441: 0.1525, cor: 3.093167
using time 38.8815, training loss at epoch 442: 0.1509, cor: 3.078881
using time 38.8352, training loss at epoch 443: 0.1520, cor: 3.107471
using time 38.9232, training loss at epoch 444: 0.1494, cor: 3.154658
using time 38.9965, training loss at epoch 445: 0.1491, cor: 3.106525
using time 38.8526, training loss at epoch 446: 0.1518, cor: 3.120704
using time 38.8439, training loss at epoch 447: 0.1474, cor: 3.105966
using time 38.8316, training loss at epoch 448: 0.1484, cor: 3.132596
+-------+-------------------+------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |   tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  449  | 38.93522024154663 | 37.8873815536499 | 0.14916804432868958 | [0.16361479 0.22685462 0.26998956 0.30340316 0.33137733] | [0.08727535 0.10345049 0.11313923 0.12014449 0.12566953] | [0.01737332 0.01254232 0.01019488 0.00875962 0.00774957] | [0.27856242 0.37105297 0.43016815 0.47309147 0.50656599] |
+-------+-------------------+------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 38.9353, training loss at epoch 450: 0.1480, cor: 3.108019
using time 39.0228, training loss at epoch 451: 0.1472, cor: 3.095723
using time 39.2973, training loss at epoch 452: 0.1451, cor: 3.184477
using time 38.9245, training loss at epoch 453: 0.1460, cor: 3.121869
using time 39.1177, training loss at epoch 454: 0.1465, cor: 3.077994
using time 38.7901, training loss at epoch 455: 0.1467, cor: 3.105175
using time 38.8774, training loss at epoch 456: 0.1443, cor: 3.077179
using time 38.9268, training loss at epoch 457: 0.1456, cor: 3.079044
using time 38.9954, training loss at epoch 458: 0.1425, cor: 3.176838
+-------+--------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time    |    tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+--------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  459  | 38.779902935028076 | 38.71053910255432 | 0.14349237084388733 | [0.16342555 0.22745981 0.27012443 0.30367206 0.33141053] | [0.08730916 0.10365465 0.1132905  0.12029038 0.12579422] | [0.01734499 0.01255224 0.01021188 0.00875944 0.0077558 ] | [0.27820827 0.37166211 0.4305648  0.47401227 0.50751512] |
+-------+--------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.5065, training loss at epoch 460: 0.1454, cor: 3.125964
using time 38.9292, training loss at epoch 461: 0.1441, cor: 3.097962
using time 38.8858, training loss at epoch 462: 0.1414, cor: 3.135262
using time 39.0518, training loss at epoch 463: 0.1394, cor: 3.235143
using time 38.9400, training loss at epoch 464: 0.1423, cor: 3.183877
using time 39.2358, training loss at epoch 465: 0.1386, cor: 3.141954
using time 38.8567, training loss at epoch 466: 0.1399, cor: 3.106450
using time 38.8546, training loss at epoch 467: 0.1390, cor: 3.106113
using time 39.1636, training loss at epoch 468: 0.1383, cor: 3.121279
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  469  | 38.90558362007141 | 40.00500226020813 | 0.13840337097644806 | [0.16319393 0.22737949 0.26975894 0.30272317 0.33014204] | [0.08745562 0.10384015 0.11339484 0.12028427 0.12572733] | [0.01732586 0.01255153 0.01019063 0.00873217 0.00772804] | [0.27771246 0.37252624 0.43018232 0.47287898 0.50619767] |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.4665, training loss at epoch 470: 0.1388, cor: 3.087636
using time 38.9553, training loss at epoch 471: 0.1396, cor: 3.070472
using time 38.8461, training loss at epoch 472: 0.1381, cor: 3.104916
using time 38.9100, training loss at epoch 473: 0.1386, cor: 3.102621
using time 39.1688, training loss at epoch 474: 0.1375, cor: 3.128021
using time 38.9091, training loss at epoch 475: 0.1389, cor: 3.119635
using time 39.0250, training loss at epoch 476: 0.1392, cor: 3.079672
using time 39.0400, training loss at epoch 477: 0.1378, cor: 3.096977
using time 38.9076, training loss at epoch 478: 0.1357, cor: 3.085512
+-------+--------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time    |    tesing time    |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+--------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  479  | 38.989612102508545 | 41.61567282676697 | 0.1348048895597458 | [0.16235596 0.22540501 0.26709373 0.30013791 0.32750203] | [0.08696417 0.10306188 0.11247694 0.11938935 0.12480472] | [0.01720262 0.01243218 0.01008509 0.00866045 0.00765678] | [0.27680583 0.3693672  0.42655579 0.46929495 0.50285447] |
+-------+--------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.3191, training loss at epoch 480: 0.1330, cor: 3.129300
using time 38.7332, training loss at epoch 481: 0.1338, cor: 3.085143
using time 39.0856, training loss at epoch 482: 0.1324, cor: 3.078625
using time 38.9403, training loss at epoch 483: 0.1334, cor: 3.052044
using time 38.7562, training loss at epoch 484: 0.1333, cor: 3.084291
using time 38.7012, training loss at epoch 485: 0.1332, cor: 3.053838
using time 39.1739, training loss at epoch 486: 0.1336, cor: 3.067094
using time 38.9215, training loss at epoch 487: 0.1322, cor: 3.091779
using time 38.9676, training loss at epoch 488: 0.1325, cor: 3.059850
+-------+--------------------+-------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time    |    tesing time    |        Loss       |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+--------------------+-------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  489  | 38.798617362976074 | 40.84736752510071 | 0.132137730717659 | [0.16376363 0.22680073 0.26999423 0.30361716 0.3310032 ] | [0.08789423 0.10401942 0.11374766 0.12077147 0.12622348] | [0.01734145 0.01252391 0.010197   0.00875483 0.00774957] | [0.27851992 0.37143545 0.4306923  0.47392727 0.50809593] |
+-------+--------------------+-------------------+-------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.0108, training loss at epoch 490: 0.1326, cor: 3.041422
using time 39.0289, training loss at epoch 491: 0.1310, cor: 3.051621
using time 38.8232, training loss at epoch 492: 0.1304, cor: 3.078493
using time 38.9057, training loss at epoch 493: 0.1302, cor: 3.062856
using time 38.9261, training loss at epoch 494: 0.1314, cor: 3.089582
using time 39.0468, training loss at epoch 495: 0.1282, cor: 3.033240
using time 38.9012, training loss at epoch 496: 0.1282, cor: 3.117245
using time 39.0738, training loss at epoch 497: 0.1292, cor: 3.098901
using time 38.9190, training loss at epoch 498: 0.1301, cor: 3.051419
+-------+-------------------+--------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time     |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+--------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  499  | 38.86336421966553 | 40.475523471832275 | 0.1281750500202179 | [0.16338979 0.22644362 0.26870641 0.30238939 0.32959019] | [0.08754555 0.10366252 0.11320571 0.12024351 0.12564241] | [0.01730886 0.01250336 0.01015734 0.00872916 0.0077177 ] | [0.27779745 0.37119463 0.42859571 0.47214234 0.50537604] |
+-------+-------------------+--------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.3497, training loss at epoch 500: 0.1259, cor: 3.053619
using time 38.8939, training loss at epoch 501: 0.1250, cor: 3.052045
using time 38.9185, training loss at epoch 502: 0.1276, cor: 3.046757
using time 38.9885, training loss at epoch 503: 0.1263, cor: 3.041986
using time 38.9160, training loss at epoch 504: 0.1240, cor: 3.061161
using time 39.0584, training loss at epoch 505: 0.1246, cor: 3.022948
using time 39.1756, training loss at epoch 506: 0.1234, cor: 2.993967
using time 38.9187, training loss at epoch 507: 0.1239, cor: 3.018744
using time 38.9041, training loss at epoch 508: 0.1242, cor: 3.029662
+-------+--------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time    |    tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+--------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  509  | 39.053584814071655 | 39.70971965789795 | 0.12459152936935425 | [0.16361282 0.22743808 0.27072875 0.30416287 0.3315625 ] | [0.08794453 0.10428089 0.11402538 0.12100743 0.12647302] | [0.01733365 0.0125657  0.010231   0.0087729  0.00776912] | [0.27779745 0.37174711 0.43125894 0.47477724 0.50785511] |
+-------+--------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.4580, training loss at epoch 510: 0.1254, cor: 3.048916
using time 38.8682, training loss at epoch 511: 0.1222, cor: 3.048085
using time 39.1360, training loss at epoch 512: 0.1220, cor: 3.033052
using time 38.9340, training loss at epoch 513: 0.1221, cor: 3.053375
using time 38.8362, training loss at epoch 514: 0.1210, cor: 3.021435
using time 38.8304, training loss at epoch 515: 0.1229, cor: 3.042366
using time 38.9221, training loss at epoch 516: 0.1208, cor: 3.001688
using time 38.7671, training loss at epoch 517: 0.1211, cor: 3.013312
using time 38.7204, training loss at epoch 518: 0.1215, cor: 3.001801
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  519  | 39.30581021308899 | 39.92142200469971 | 0.12189120054244995 | [0.16248079 0.22616993 0.2686945  0.30233333 0.32945708] | [0.08748011 0.10376052 0.11331784 0.12032966 0.12572738] | [0.01723591 0.0124853  0.01013585 0.00870171 0.00769999] | [0.27642334 0.37048632 0.42863821 0.47226984 0.50563103] |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.5099, training loss at epoch 520: 0.1222, cor: 2.992227
using time 38.8339, training loss at epoch 521: 0.1172, cor: 2.979524
using time 38.8277, training loss at epoch 522: 0.1193, cor: 3.046250
using time 39.0151, training loss at epoch 523: 0.1171, cor: 3.018339
using time 39.0393, training loss at epoch 524: 0.1187, cor: 3.009511
using time 38.8990, training loss at epoch 525: 0.1186, cor: 2.984968
using time 38.8431, training loss at epoch 526: 0.1197, cor: 2.971824
using time 38.7279, training loss at epoch 527: 0.1155, cor: 3.004014
using time 38.9102, training loss at epoch 528: 0.1165, cor: 3.002493
+-------+--------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time    |    tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+--------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  529  | 38.670101165771484 | 40.47484493255615 | 0.11433272063732147 | [0.1627967  0.22623709 0.26921212 0.30228244 0.33010531] | [0.08779312 0.10403242 0.11368257 0.12059854 0.12613642] | [0.01725503 0.01250266 0.0101571  0.00870915 0.00772365] | [0.27677749 0.37129379 0.42921902 0.47178819 0.50578686] |
+-------+--------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.4241, training loss at epoch 530: 0.1180, cor: 2.968039
using time 39.0409, training loss at epoch 531: 0.1186, cor: 3.012177
using time 38.9276, training loss at epoch 532: 0.1132, cor: 3.030272
using time 38.8308, training loss at epoch 533: 0.1170, cor: 3.008986
using time 39.0123, training loss at epoch 534: 0.1151, cor: 3.012419
using time 38.8685, training loss at epoch 535: 0.1160, cor: 2.994632
using time 38.9206, training loss at epoch 536: 0.1163, cor: 3.000976
using time 38.7900, training loss at epoch 537: 0.1170, cor: 2.971440
using time 39.0992, training loss at epoch 538: 0.1143, cor: 3.016934
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  539  | 38.74815249443054 | 40.50875735282898 | 0.11515163630247116 | [0.16489823 0.22797831 0.27017027 0.30346215 0.33159556] | [0.08840579 0.1045605  0.11403351 0.12100758 0.12660352] | [0.01743636 0.01258447 0.01017693 0.00873837 0.00775595] | [0.27921406 0.3728379  0.43100395 0.47319063 0.5073168 ] |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 38.8485, training loss at epoch 540: 0.1151, cor: 2.977848
using time 38.8799, training loss at epoch 541: 0.1136, cor: 3.005654
using time 38.9821, training loss at epoch 542: 0.1113, cor: 2.989048
using time 38.8287, training loss at epoch 543: 0.1139, cor: 2.982880
using time 39.0179, training loss at epoch 544: 0.1116, cor: 2.984756
using time 38.9820, training loss at epoch 545: 0.1144, cor: 2.991407
using time 38.9869, training loss at epoch 546: 0.1121, cor: 2.993858
using time 38.8032, training loss at epoch 547: 0.1140, cor: 2.971897
using time 38.8190, training loss at epoch 548: 0.1114, cor: 2.965168
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  549  | 38.81746172904968 | 41.70630717277527 | 0.1108575090765953 | [0.16237939 0.22674216 0.26909868 0.30257271 0.33023241] | [0.08729854 0.10372419 0.11327664 0.12028424 0.12576065] | [0.01721608 0.01249522 0.01015332 0.00872615 0.00771841] | [0.27611169 0.37166211 0.42971484 0.47246816 0.50619767] |
+-------+-------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.4394, training loss at epoch 550: 0.1112, cor: 2.991634
using time 39.0487, training loss at epoch 551: 0.1105, cor: 2.954191
using time 38.8033, training loss at epoch 552: 0.1087, cor: 2.949780
using time 38.8176, training loss at epoch 553: 0.1091, cor: 2.970037
using time 38.9255, training loss at epoch 554: 0.1112, cor: 2.973300
using time 38.8615, training loss at epoch 555: 0.1108, cor: 2.946222
using time 38.8495, training loss at epoch 556: 0.1089, cor: 2.995461
using time 39.0000, training loss at epoch 557: 0.1093, cor: 3.002352
using time 38.9106, training loss at epoch 558: 0.1087, cor: 2.963148
+-------+--------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time    |    tesing time     |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+--------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  559  | 39.019001960754395 | 40.167333126068115 | 0.10909557342529297 | [0.16175747 0.2241919  0.26729218 0.30060129 0.32737648] | [0.08690315 0.10285639 0.11253759 0.11951046 0.12483382] | [0.01713604 0.0123617  0.01007423 0.00865461 0.00765126] | [0.27428426 0.36776643 0.4273066  0.47013075 0.50237282] |
+-------+--------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.3748, training loss at epoch 560: 0.1072, cor: 2.975428
using time 38.8901, training loss at epoch 561: 0.1072, cor: 2.975978
using time 39.2095, training loss at epoch 562: 0.1082, cor: 2.952452
using time 38.9456, training loss at epoch 563: 0.1087, cor: 2.966453
using time 38.9432, training loss at epoch 564: 0.1079, cor: 2.969542
using time 38.8312, training loss at epoch 565: 0.1043, cor: 2.942570
using time 38.9307, training loss at epoch 566: 0.1073, cor: 2.960403
using time 38.8330, training loss at epoch 567: 0.1054, cor: 2.966886
using time 39.0003, training loss at epoch 568: 0.1058, cor: 2.951581
+-------+--------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time    |    tesing time     |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+--------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  569  | 38.976158142089844 | 38.269458055496216 | 0.10712296515703201 | [0.16256472 0.22541495 0.26826868 0.30177758 0.32933167] | [0.08737802 0.10347466 0.11308627 0.12008643 0.12556495] | [0.01718208 0.01243855 0.01010563 0.0086856  0.00769319] | [0.27567254 0.37003301 0.42862405 0.47178819 0.50490856] |
+-------+--------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.2783, training loss at epoch 570: 0.1057, cor: 2.939382
using time 38.9901, training loss at epoch 571: 0.1041, cor: 2.926220
using time 38.8430, training loss at epoch 572: 0.1049, cor: 2.951808
using time 39.3837, training loss at epoch 573: 0.1044, cor: 2.937791
using time 39.7255, training loss at epoch 574: 0.1026, cor: 2.902378
using time 39.4200, training loss at epoch 575: 0.1032, cor: 2.948155
using time 39.5467, training loss at epoch 576: 0.1032, cor: 2.931944
using time 39.3764, training loss at epoch 577: 0.1033, cor: 3.011933
using time 39.4591, training loss at epoch 578: 0.1035, cor: 2.974115
+-------+--------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time    |    tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+--------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  579  | 39.577213764190674 | 38.37543487548828 | 0.10273775458335876 | [0.16318378 0.22609198 0.26916473 0.30336554 0.3314479 ] | [0.08760426 0.10370162 0.11339092 0.12052028 0.12611667] | [0.0172607  0.01246228 0.01014553 0.0087281  0.0077449 ] | [0.27700415 0.37044382 0.42988483 0.47365812 0.50750096] |
+-------+--------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.8231, training loss at epoch 580: 0.1032, cor: 2.925901
using time 39.6154, training loss at epoch 581: 0.1024, cor: 2.923387
using time 39.4448, training loss at epoch 582: 0.1019, cor: 2.935875
using time 39.3917, training loss at epoch 583: 0.1012, cor: 2.932268
using time 39.3602, training loss at epoch 584: 0.1003, cor: 2.915141
using time 39.4962, training loss at epoch 585: 0.0997, cor: 2.904993
using time 39.2283, training loss at epoch 586: 0.1005, cor: 2.961740
using time 38.7336, training loss at epoch 587: 0.1011, cor: 2.951980
using time 38.8643, training loss at epoch 588: 0.1000, cor: 2.929113
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  589  | 38.86600112915039 | 39.28749489784241 | 0.10236147791147232 | [0.16246025 0.2249317  0.2681242  0.30206149 0.32890421] | [0.08753616 0.10349329 0.11319703 0.12029343 0.12564065] | [0.01717783 0.01237622 0.01008958 0.00868772 0.00768016] | [0.27558754 0.36854557 0.42815656 0.47160403 0.50398776] |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.4636, training loss at epoch 590: 0.0980, cor: 2.988682
using time 38.9800, training loss at epoch 591: 0.1003, cor: 2.942961
using time 39.0521, training loss at epoch 592: 0.1002, cor: 2.922981
using time 39.1532, training loss at epoch 593: 0.1006, cor: 2.922925
using time 38.9919, training loss at epoch 594: 0.0991, cor: 2.907884
using time 39.1123, training loss at epoch 595: 0.0978, cor: 2.933049
using time 39.0970, training loss at epoch 596: 0.0985, cor: 2.901685
using time 38.8104, training loss at epoch 597: 0.0991, cor: 2.921116
using time 38.9981, training loss at epoch 598: 0.0969, cor: 2.914084
+-------+------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |  training time   |    tesing time    |        Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  599  | 39.0799400806427 | 40.51497769355774 | 0.0971304327249527 | [0.16292812 0.22623838 0.26861959 0.30264161 0.32999638] | [0.08768736 0.10384347 0.11340163 0.12050816 0.12593413] | [0.01723591 0.01244103 0.01011838 0.00870649 0.00770183] | [0.27642334 0.36997634 0.42862405 0.47221317 0.50462524] |
+-------+------------------+-------------------+--------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.5506, training loss at epoch 600: 0.0982, cor: 2.911628
using time 38.8695, training loss at epoch 601: 0.0994, cor: 3.088869
using time 38.9458, training loss at epoch 602: 0.0973, cor: 3.127165
using time 38.8101, training loss at epoch 603: 0.0980, cor: 3.039380
using time 38.8994, training loss at epoch 604: 0.0983, cor: 2.989444
using time 38.8624, training loss at epoch 605: 0.0972, cor: 2.946483
using time 39.0863, training loss at epoch 606: 0.0976, cor: 2.933974
using time 38.8019, training loss at epoch 607: 0.0950, cor: 2.916619
using time 38.8784, training loss at epoch 608: 0.0957, cor: 2.889067
+-------+-------------------+------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |   tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  609  | 38.79636526107788 | 38.9882709980011 | 0.09630763530731201 | [0.16278263 0.22590071 0.26812029 0.30189815 0.32953822] | [0.08781628 0.10393432 0.11346156 0.12051651 0.12600465] | [0.01717287 0.01239889 0.01008297 0.00867426 0.00768186] | [0.27571503 0.36916887 0.42778824 0.47122154 0.50418609] |
+-------+-------------------+------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.8663, training loss at epoch 610: 0.0956, cor: 2.880632
using time 38.8386, training loss at epoch 611: 0.0961, cor: 2.838623
using time 38.8791, training loss at epoch 612: 0.0948, cor: 2.866354
using time 39.2522, training loss at epoch 613: 0.0944, cor: 2.859873
using time 39.1237, training loss at epoch 614: 0.0967, cor: 2.831849
using time 39.2305, training loss at epoch 615: 0.0924, cor: 2.847048
using time 38.9478, training loss at epoch 616: 0.0952, cor: 2.816794
using time 38.9700, training loss at epoch 617: 0.0924, cor: 2.811221
using time 39.1059, training loss at epoch 618: 0.0935, cor: 2.830434
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  619  | 39.00152659416199 | 40.97845721244812 | 0.09242536127567291 | [0.16462698 0.22755314 0.27066719 0.30417765 0.33144441] | [0.08875767 0.10486729 0.11456866 0.12155787 0.12697421] | [0.0174144  0.01254622 0.01020456 0.00875023 0.00773654] | [0.27880325 0.3717896  0.43121644 0.47364395 0.50612684] |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.3077, training loss at epoch 620: 0.0939, cor: 2.803428
using time 38.8446, training loss at epoch 621: 0.0930, cor: 2.868764
using time 39.1430, training loss at epoch 622: 0.0945, cor: 2.840184
using time 38.9144, training loss at epoch 623: 0.0932, cor: 2.809583
using time 38.8996, training loss at epoch 624: 0.0922, cor: 2.779315
using time 38.8307, training loss at epoch 625: 0.0908, cor: 2.836803
using time 39.0475, training loss at epoch 626: 0.0919, cor: 2.800734
using time 38.7648, training loss at epoch 627: 0.0916, cor: 2.793984
using time 38.8446, training loss at epoch 628: 0.0913, cor: 2.836085
+-------+-------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time     |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  629  | 38.84649920463562 | 37.933778524398804 | 0.09174074232578278 | [0.16346848 0.2267021  0.26935796 0.3027039  0.32971891] | [0.08824733 0.10442101 0.11402137 0.12097532 0.12633931] | [0.0172437  0.01246795 0.01013609 0.00869445 0.00768129] | [0.27703248 0.37064215 0.42945985 0.47234067 0.50506438] |
+-------+-------------------+--------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
using time 39.2582, training loss at epoch 630: 0.0906, cor: 2.808430
using time 38.8583, training loss at epoch 631: 0.0911, cor: 2.891572
using time 38.9900, training loss at epoch 632: 0.0900, cor: 3.028474
using time 38.8735, training loss at epoch 633: 0.0885, cor: 2.952069
using time 38.8527, training loss at epoch 634: 0.0894, cor: 2.868318
using time 38.8846, training loss at epoch 635: 0.0885, cor: 2.835878
using time 38.7779, training loss at epoch 636: 0.0883, cor: 2.824762
using time 39.0651, training loss at epoch 637: 0.0888, cor: 2.809531
using time 38.8669, training loss at epoch 638: 0.0881, cor: 2.800901
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
| Epoch |   training time   |    tesing time    |         Loss        |                          recall                          |                           ndcg                           |                        precision                         |                        hit_ratio                         |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
|  639  | 38.78797745704651 | 40.22731685638428 | 0.08814409375190735 | [0.16289648 0.22662566 0.26928296 0.30216955 0.32959758] | [0.08801135 0.10430231 0.11390364 0.12079028 0.12624562] | [0.01719412 0.01245166 0.01012027 0.00868046 0.00768497] | [0.27574337 0.37023133 0.4289782  0.47147653 0.50454024] |
+-------+-------------------+-------------------+---------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+----------------------------------------------------------+
Early stopping is trigger at step: 10 log:0.16289647995212997
early stopping at 639, recall@20:0.1649
